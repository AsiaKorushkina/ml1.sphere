{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 25 ноября 2019, 15:00   \n",
    "**Штраф за опоздание:** -2 балла после 15:00 25 ноября, -4 балла после 15:00 2 декабря, -6 баллов после 15:00 9 декабря  -8 баллов после 15:00 16 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0919, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и [Speed Dating Data](https://cloud.mail.ru/public/8nHV/p6J7wY1y1)\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - np.sum((l_c ** 2) / (l_s * (l_s + r_s)) +\n",
    "                          (r_c ** 2) / (r_s * (l_s + r_s)), axis=1)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -np.sum(l_c/l_s * np.log2(l_c/l_s), axis=1) - np.sum(\n",
    "            r_c/r_s*np.log2(r_c/r_s), axis=1)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - np.max(l_c / (l_s + r_s), axis=1) - np.max(\n",
    "            r_c / (l_s + r_s), axis=1)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.sqrt(n_feature))])\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:int(np.log2(n_feature))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        x_sort, y_sort=self.__sort_samples(x,y)\n",
    "        class_num=self.num_class\n",
    "        cut = np.int(self.min_samples_split / 2 - 1)\n",
    "        y_sort_slit = y_sort[cut:-cut] if cut != 0 else y_sort\n",
    "        r_border_ids = np.where(y_sort_slit[:-1] != y_sort_slit[1:])[0] + (cut + 1)\n",
    "        \n",
    "        if len(r_border_ids) == 0:\n",
    "            return np.inf, None\n",
    "        \n",
    "        eq_el_count = r_border_ids - np.append([cut], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_num))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]),\n",
    "                     y_sort[r_border_ids - 1]] = 1\n",
    "        \n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(y_sort[:cut], minlength=class_num)\n",
    "\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(y_sort, minlength=class_num) - l_class_count\n",
    "    \n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = y_sort.shape[0] - l_sizes\n",
    "\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        indx = np.argmin(gs)\n",
    "        \n",
    "        left_el_id = l_sizes[indx][0]\n",
    "        \n",
    "        return gs[indx], (x_sort[left_el_id - 1] + x_sort[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        if (self.max_depth is not None and self.max_depth<=depth) or \\\n",
    "            y.size < self.min_samples_split or \\\n",
    "            self.sufficient_share <= np.bincount(y).argmax() / y.size:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "        threshold = np.array([self.__find_threshold(x[:, i], y)\n",
    "                              for i in self.get_feature_ids(x.shape[1])])\n",
    "        best_id = threshold[:, 0].argmin()\n",
    "        best_threshold = threshold[best_id, 1]\n",
    "        \n",
    "        if best_threshold == None:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(),\n",
    "                                  np.bincount(y).astype(float) / y.size)\n",
    "        else:\n",
    "            x_l, x_r, y_l, y_r =self.__div_samples(x, y,\n",
    "                                                   best_id, best_threshold)\n",
    "            if x_l.size == 0 or x_r.size == 0:\n",
    "                self.tree[node_id] = (self.LEAF_TYPE,np.bincount(y).argmax(),\n",
    "                                      np.bincount(y).astype(float) / y.size)\n",
    "            else:\n",
    "                self.tree[node_id] = (self.NON_LEAF_TYPE,\n",
    "                                      best_id, best_threshold)\n",
    "                self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "                self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "            if self.G_function == self.__gini:\n",
    "                g_r=(1 - np.sum(np.unique(y_r, return_counts=True)[1] ** 2 /\n",
    "                                y_r.size ** 2))\n",
    "                g=(1 - np.sum(np.unique(y, return_counts=True)[1]** 2 /\n",
    "                              y.size ** 2))\n",
    "                g_l=(1 - np.sum(np.unique(y_l, return_counts=True)[1] ** 2 /\n",
    "                                y_l.size ** 2))\n",
    "            if self.G_function == self.__entropy:\n",
    "                g_r=-(np.sum((np.unique(y_r, return_counts=True)[1] / y_r.size) *\n",
    "                             np.log2(np.unique(y_r, return_counts=True)[1] / y_r.size)))\n",
    "                g=-(np.sum((np.unique(y, return_counts=True)[1] / y.size) *\n",
    "                           np.log2(np.unique(y, return_counts=True)[1] / y.size)))\n",
    "                g_l=-(np.sum((np.unique(y_l, return_counts=True)[1] / y_l.size) *\n",
    "                             np.log2(np.unique(y_l, return_counts=True)[1] / y_l.size)))  \n",
    "            elif self.G_function == self.__misclass:\n",
    "                g_r=(1 - np.max(np.sum(np.unique(y_r, return_counts=True)[1] / y.size)))\n",
    "                g=(1 - np.max(np.sum(np.unique(y, return_counts=True)[1] / y.size)))\n",
    "                g_l=(1 - np.max(np.sum(np.unique(y_l, return_counts=True)[1] / y.size)))\n",
    "            self.feature_importances_[best_id] += (y.size*g - y_l.size*g_l - y_r.size*g_r)\n",
    "            / y.size\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 195 entries, iid to amb5_3\n",
      "dtypes: float64(174), int64(13), object(8)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/speed-dating-experiment/Speed Dating Data.csv', encoding='cp1251')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if type(df[i][0]) not in [np.float64, np.int64]:\n",
    "        df.drop(i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 187 entries, iid to amb5_3\n",
      "dtypes: float64(174), int64(13)\n",
      "memory usage: 12.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].isnull().sum()>500:\n",
    "        df.drop(i,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 82 columns):\n",
      "iid         8378 non-null int64\n",
      "id          8377 non-null float64\n",
      "gender      8378 non-null int64\n",
      "idg         8378 non-null int64\n",
      "condtn      8378 non-null int64\n",
      "wave        8378 non-null int64\n",
      "round       8378 non-null int64\n",
      "position    8378 non-null int64\n",
      "order       8378 non-null int64\n",
      "partner     8378 non-null int64\n",
      "pid         8368 non-null float64\n",
      "match       8378 non-null int64\n",
      "int_corr    8220 non-null float64\n",
      "samerace    8378 non-null int64\n",
      "age_o       8274 non-null float64\n",
      "race_o      8305 non-null float64\n",
      "pf_o_att    8289 non-null float64\n",
      "pf_o_sin    8289 non-null float64\n",
      "pf_o_int    8289 non-null float64\n",
      "pf_o_fun    8280 non-null float64\n",
      "pf_o_amb    8271 non-null float64\n",
      "pf_o_sha    8249 non-null float64\n",
      "dec_o       8378 non-null int64\n",
      "attr_o      8166 non-null float64\n",
      "sinc_o      8091 non-null float64\n",
      "intel_o     8072 non-null float64\n",
      "fun_o       8018 non-null float64\n",
      "like_o      8128 non-null float64\n",
      "prob_o      8060 non-null float64\n",
      "met_o       7993 non-null float64\n",
      "age         8283 non-null float64\n",
      "field_cd    8296 non-null float64\n",
      "race        8315 non-null float64\n",
      "imprace     8299 non-null float64\n",
      "imprelig    8299 non-null float64\n",
      "goal        8299 non-null float64\n",
      "date        8281 non-null float64\n",
      "go_out      8299 non-null float64\n",
      "career_c    8240 non-null float64\n",
      "sports      8299 non-null float64\n",
      "tvsports    8299 non-null float64\n",
      "exercise    8299 non-null float64\n",
      "dining      8299 non-null float64\n",
      "museums     8299 non-null float64\n",
      "art         8299 non-null float64\n",
      "hiking      8299 non-null float64\n",
      "gaming      8299 non-null float64\n",
      "clubbing    8299 non-null float64\n",
      "reading     8299 non-null float64\n",
      "tv          8299 non-null float64\n",
      "theater     8299 non-null float64\n",
      "movies      8299 non-null float64\n",
      "concerts    8299 non-null float64\n",
      "music       8299 non-null float64\n",
      "shopping    8299 non-null float64\n",
      "yoga        8299 non-null float64\n",
      "exphappy    8277 non-null float64\n",
      "attr1_1     8299 non-null float64\n",
      "sinc1_1     8299 non-null float64\n",
      "intel1_1    8299 non-null float64\n",
      "fun1_1      8289 non-null float64\n",
      "amb1_1      8279 non-null float64\n",
      "shar1_1     8257 non-null float64\n",
      "attr2_1     8299 non-null float64\n",
      "sinc2_1     8299 non-null float64\n",
      "intel2_1    8299 non-null float64\n",
      "fun2_1      8299 non-null float64\n",
      "amb2_1      8289 non-null float64\n",
      "shar2_1     8289 non-null float64\n",
      "attr3_1     8273 non-null float64\n",
      "sinc3_1     8273 non-null float64\n",
      "fun3_1      8273 non-null float64\n",
      "intel3_1    8273 non-null float64\n",
      "amb3_1      8273 non-null float64\n",
      "dec         8378 non-null int64\n",
      "attr        8176 non-null float64\n",
      "sinc        8101 non-null float64\n",
      "intel       8082 non-null float64\n",
      "fun         8028 non-null float64\n",
      "like        8138 non-null float64\n",
      "prob        8069 non-null float64\n",
      "met         8003 non-null float64\n",
      "dtypes: float64(69), int64(13)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>dec</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8373</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>526.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8374</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>527.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8375</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>528.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8376</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>529.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8377</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>530.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  gender  idg  condtn  wave  round  position  order  partner    pid  \\\n",
       "0       1       0    1       1     1     10         7      4        1   11.0   \n",
       "1       1       0    1       1     1     10         7      3        2   12.0   \n",
       "2       1       0    1       1     1     10         7     10        3   13.0   \n",
       "3       1       0    1       1     1     10         7      5        4   14.0   \n",
       "4       1       0    1       1     1     10         7      7        5   15.0   \n",
       "...   ...     ...  ...     ...   ...    ...       ...    ...      ...    ...   \n",
       "8373  552       1   44       2    21     22        14      5       18  526.0   \n",
       "8374  552       1   44       2    21     22        13      4       19  527.0   \n",
       "8375  552       1   44       2    21     22        19     10       20  528.0   \n",
       "8376  552       1   44       2    21     22         3     16       21  529.0   \n",
       "8377  552       1   44       2    21     22         2     15       22  530.0   \n",
       "\n",
       "      ...  intel3_1  amb3_1  dec  attr  sinc  intel  fun  like  prob  met  \n",
       "0     ...       8.0     7.0    1   6.0   9.0    7.0  7.0   7.0   6.0  2.0  \n",
       "1     ...       8.0     7.0    1   7.0   8.0    7.0  8.0   7.0   5.0  1.0  \n",
       "2     ...       8.0     7.0    1   5.0   8.0    9.0  8.0   7.0   NaN  1.0  \n",
       "3     ...       8.0     7.0    1   7.0   6.0    8.0  7.0   7.0   6.0  2.0  \n",
       "4     ...       8.0     7.0    1   5.0   6.0    7.0  7.0   6.0   6.0  2.0  \n",
       "...   ...       ...     ...  ...   ...   ...    ...  ...   ...   ...  ...  \n",
       "8373  ...       7.0     7.0    0   3.0   5.0    5.0  5.0   2.0   5.0  0.0  \n",
       "8374  ...       7.0     7.0    0   4.0   6.0    8.0  4.0   4.0   4.0  0.0  \n",
       "8375  ...       7.0     7.0    0   4.0   7.0    8.0  8.0   6.0   5.0  0.0  \n",
       "8376  ...       7.0     7.0    0   4.0   6.0    5.0  4.0   5.0   5.0  0.0  \n",
       "8377  ...       7.0     7.0    0   3.0   7.0    6.0  4.0   4.0   5.0  0.0  \n",
       "\n",
       "[8378 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:, 'gender'].values\n",
    "df=df.fillna(-8888)\n",
    "X=df.drop('gender', axis=1).iloc[:,0:].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3)\n",
    "myclf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 239 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')\n",
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')\n",
    "%time myclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9896538231659138"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тут должен быть код типа %time clf.fit(X_train, y_train)\n",
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761016469013575"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тут должен быть код типа %time my_clf.fit(X_train, y_train)\n",
    "f1_score(y_pred=myclf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr1_1     0.237565\n",
      "attr2_1     0.161761\n",
      "pf_o_att    0.105738\n",
      "shopping    0.052974\n",
      "id          0.036227\n",
      "amb2_1      0.033847\n",
      "intel2_1    0.027798\n",
      "amb1_1      0.023603\n",
      "exphappy    0.023555\n",
      "imprace     0.021547\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(data=clf.feature_importances_,\n",
    "          index=df.columns[1:]).sort_values(ascending=False)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr1_1     722.435629\n",
      "attr2_1     460.798461\n",
      "pf_o_att    338.293168\n",
      "id          172.872364\n",
      "amb1_1      172.371334\n",
      "shopping     96.829168\n",
      "amb2_1       74.107186\n",
      "intel2_1     73.837510\n",
      "sports       53.913357\n",
      "date         50.619175\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(data=myclf.feature_importances_, \n",
    "        index=df.columns[1:]).sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asia\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15, 'min_samples_split': 4, 'max_depth': 12, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9988063333653565"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametrs = {\n",
    "    \"min_samples_split\": [i for i in range(2, 20, 2)],\n",
    "    \"max_depth\": [i for i in range(2, 20, 2)],\n",
    "    \"n_estimators\": [i for i in range(1, 20,2)],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "RSCV = RandomizedSearchCV(RandomForestClassifier(random_state=123), param_distributions=parametrs, n_iter=75)\n",
    "RSCV.fit(X_train, y_train)\n",
    "print(RSCV.best_params_)\n",
    "f1_score(y_pred=RSCV.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
